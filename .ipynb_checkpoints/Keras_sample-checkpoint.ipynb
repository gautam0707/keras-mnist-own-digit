{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - Mnist - image recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import math\n",
    "import keras\n",
    "import cv2\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "num_classes=10\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data ,shuffled and split between train and test sets\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(60000,784)\n",
    "x_test=x_test.reshape(10000,784)\n",
    "\n",
    "x_train=x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "\n",
    "x_train /=255\n",
    "x_test /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0],'train samples')\n",
    "print(x_test.shape[0],'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert class vectors to binary class matrices\n",
    "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test=keras.utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(512,activation='relu',input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.2434 - acc: 0.9244 - val_loss: 0.1019 - val_acc: 0.9671\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1024 - acc: 0.9691 - val_loss: 0.0806 - val_acc: 0.9745\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0747 - acc: 0.9767 - val_loss: 0.0746 - val_acc: 0.9785\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0596 - acc: 0.9823 - val_loss: 0.0750 - val_acc: 0.9805\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0504 - acc: 0.9849 - val_loss: 0.0733 - val_acc: 0.9803\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0443 - acc: 0.9870 - val_loss: 0.0825 - val_acc: 0.9799\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0396 - acc: 0.9880 - val_loss: 0.0849 - val_acc: 0.9816\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0348 - acc: 0.9901 - val_loss: 0.0816 - val_acc: 0.9809\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0324 - acc: 0.9909 - val_loss: 0.0821 - val_acc: 0.9838\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0284 - acc: 0.9915 - val_loss: 0.0849 - val_acc: 0.9826\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0272 - acc: 0.9924 - val_loss: 0.0955 - val_acc: 0.9810\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0245 - acc: 0.9935 - val_loss: 0.0829 - val_acc: 0.9834\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0249 - acc: 0.9932 - val_loss: 0.0901 - val_acc: 0.9843\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0207 - acc: 0.9944 - val_loss: 0.1027 - val_acc: 0.9819\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0228 - acc: 0.9940 - val_loss: 0.1048 - val_acc: 0.9806\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0198 - acc: 0.9946 - val_loss: 0.0999 - val_acc: 0.9825\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0200 - acc: 0.9949 - val_loss: 0.1142 - val_acc: 0.9826\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0194 - acc: 0.9947 - val_loss: 0.1069 - val_acc: 0.9835\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0187 - acc: 0.9951 - val_loss: 0.0980 - val_acc: 0.9850\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0180 - acc: 0.9954 - val_loss: 0.0963 - val_acc: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20eccb56eb8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0962843564058\n",
      "Test accuracy: 0.9845\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBestShift(img):\n",
    "    cy,cx = ndimage.measurements.center_of_mass(img)\n",
    "\n",
    "    rows,cols = img.shape\n",
    "    shiftx = np.round(cols/2.0-cx).astype(int)\n",
    "    shifty = np.round(rows/2.0-cy).astype(int)\n",
    "\n",
    "    return shiftx,shifty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift(img,sx,sy):\n",
    "    rows,cols = img.shape\n",
    "    M = np.float32([[1,0,sx],[0,1,sy]])\n",
    "    shifted = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_own_img(img):\n",
    "    gray = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "    gray = cv2.resize(255-gray, (28, 28))\n",
    "    (thresh, gray) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    cv2.imwrite(\"not\"+img, gray)\n",
    "    while np.sum(gray[0]) == 0:\n",
    "        gray = gray[1:]\n",
    "\n",
    "    while np.sum(gray[:,0]) == 0:\n",
    "        gray = np.delete(gray,0,1)\n",
    "\n",
    "    while np.sum(gray[-1]) == 0:\n",
    "        gray = gray[:-1]\n",
    "\n",
    "    while np.sum(gray[:,-1]) == 0:\n",
    "        gray = np.delete(gray,-1,1)\n",
    "\n",
    "    rows,cols = gray.shape\n",
    "\n",
    "    if rows > cols:\n",
    "        factor = 20.0/rows\n",
    "        rows = 20\n",
    "        cols = int(round(cols*factor))\n",
    "        # first cols than rows\n",
    "        gray = cv2.resize(gray, (cols,rows))\n",
    "    else:\n",
    "        factor = 20.0/cols\n",
    "        cols = 20\n",
    "        rows = int(round(rows*factor))\n",
    "        # first cols than rows\n",
    "        gray = cv2.resize(gray, (cols, rows))\n",
    "    \n",
    "    \n",
    "    colsPadding = (int(math.ceil((28-cols)/2.0)),int(math.floor((28-cols)/2.0)))\n",
    "    rowsPadding = (int(math.ceil((28-rows)/2.0)),int(math.floor((28-rows)/2.0)))\n",
    "    \n",
    "    gray = np.lib.pad(gray,(rowsPadding,colsPadding),'constant')\n",
    "\n",
    "    shiftx,shifty = getBestShift(gray)\n",
    "    shifted = shift(gray,shiftx,shifty)\n",
    "    gray = shifted\n",
    "    cv2.imwrite(\"not_1\"+img, gray)\n",
    "    gray = gray/255\n",
    "    print(np.argmax(model.predict(gray.reshape(1,784))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 20\n",
      "(6, 6) (4, 4)\n",
      "0\n",
      "20 16\n",
      "(4, 4) (6, 6)\n",
      "3\n",
      "20 14\n",
      "(4, 4) (7, 7)\n",
      "4\n",
      "20 15\n",
      "(4, 4) (7, 6)\n",
      "8\n",
      "17 20\n",
      "(6, 5) (4, 4)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "test_own_img('0.png')\n",
    "test_own_img('3.png')\n",
    "test_own_img('4.png')\n",
    "test_own_img('8.png')\n",
    "test_own_img('shekar_4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
